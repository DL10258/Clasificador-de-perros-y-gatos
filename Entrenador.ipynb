{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador de imagenes de perros y gatos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrantes del grupo\n",
    "- Ramirez Mendoza, Jorge Luis\n",
    "- Huaman Huamani, Alexander Fermin\n",
    "- Obeso Sanchez, Aldo Alessandro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas necesarias para el proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf #biblioteca principal de TensorFlow.\n",
    "import tensorflow_datasets as tfds #conjuntos de datos predefinidos para el entrenamiento y evaluación de modelos\n",
    "from tensorflow.keras.layers import Dense, Flatten #capas de la red neuronal\n",
    "from tensorflow.keras.models import Sequential #modelo secuencial que combina capas en secuencia\n",
    "from tensorflow.keras.applications import VGG16 #clase proporcionada por TensorFlow que implementa la arquitectura del modelo VGG16."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del conjunto de datos desde TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos, metadatos = tfds.load('cats_vs_dogs', split='train[:80%]', shuffle_files=True, with_info=True, as_supervised=True)\n",
    "# La función tfds.load devuelve dos valores: datos y metadatos. El valor datos contiene el conjunto de datos cargado, que consiste en las imágenes y las etiquetas. El valor metadatos contiene información adicional sobre el conjunto de datos, como el número total de imágenes, las etiquetas disponibles, entre otros detalles.\n",
    "#'cats_vs_dogs' Es el nombre del conjunto de datos que se va a cargar.\n",
    "# split='train[:80%]' Indica qué porción del conjunto de datos se utilizará para entrenamiento. En este caso, se especifica que se desea utilizar el 80% de las imágenes para entrenamiento. El 20% restante se reservará para la validación.\n",
    "# shuffle_files=True Esta opción indica si se deben mezclar los archivos del conjunto de datos.\n",
    "# with_info=True Esta opción indica que se desea obtener información adicional sobre el conjunto de datos, como metadatos, junto con los datos mismos\n",
    "# as_supervised=True Esta opción especifica que se desea cargar los datos en forma de pares (imagen, etiqueta) donde la imagen es la entrada y la etiqueta es la clase (perro o gato) correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_entrenamiento = datos.take(int(0.8 * metadatos.splits['train'].num_examples))\n",
    "# datos: Es el conjunto de datos cargado, que contiene las imágenes y etiqueta\n",
    "# metadatos.splits['train'].num_examples: Devuelve el número total de ejemplos en el subconjunto de entrenamiento\n",
    "# int(0.8 * metadatos.splits['train'].num_examples): Calcula el 80% de los ejemplos de entrenamiento y redondea al entero más cercano\n",
    "# datos.take( ): Toma los primeros n ejemplos del conjunto de datos, donde n es el número calculado anteriormente\n",
    "# Esta línea de código selecciona el 80% de los ejemplos de entrenamiento del conjunto de datos completo y los asigna a la variable \n",
    "datos_validacion = datos.skip(int(0.8 * metadatos.splits['train'].num_examples))\n",
    "# datos.skip( ): Omite los primeros n ejemplos del conjunto de datos, donde n es el número calculado anteriormente\n",
    "# Esta línea de código omite el 80% de los ejemplos de entrenamiento del conjunto de datos completo y asigna el resto (20%) a la variable datos_validacion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizacion y redimension de las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "datos_entrenamiento = datos_entrenamiento.map(preprocess_image)\n",
    "datos_validacion = datos_validacion.map(preprocess_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicion del modelo base pre-entrenado utilizando la arquitectura VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "# Configuramos el modelo para que no entrene las capas del modelo base, estableciendo base_model.trainable = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construccion del modelo completo agregando capas adicionales a la arquitectura base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilamos el modelo especificando el optimizador, la función de pérdida y las métricas a utilizar durante el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos la extensión de TensorBoard para visualizar los registros de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos la ubicación para guardar los registros de TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos un callback de TensorBoard para registrar los datos durante el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos el modelo utilizando los datos de entrenamiento y validación, especificando el número de épocas y el callback de TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(datos_entrenamiento.batch(32),\n",
    "          validation_data=datos_validacion.batch(32),\n",
    "          epochs=10,\n",
    "          callbacks=[tensorboard_callback])\n",
    "# Este código carga un conjunto de datos de perros y gatos, construye un modelo de clasificación de imágenes utilizando la arquitectura VGG16 como base pre-entrenada, y luego lo entrena utilizando el optimizador Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/\n",
    "# Aqui debia de iniciar el tensorBoard, pero el proyecto se hizo en GoogleColab y por algun motivo siempre salto el error 403 cada que se quizo caragar TensorBoard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se guarda el modelo entrenado obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelo_perros_gatos.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
